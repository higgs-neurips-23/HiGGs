{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5fc7b-180b-4ce4-89a1-7d2574553d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import torch\n",
    "import networkx.algorithms.community as comm\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "from torch_geometric.io import read_npz\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from bter.bter import BTER\n",
    "os.chdir(\"notepad_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae91df-ea0e-4336-aeaf-a64d3c94741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('../../dgd/')\n",
    "# print(os.getcwd())\n",
    "\n",
    "def load_original(name = None, largest_cc = True):\n",
    "    print(f\"Loading original {name} graph\")\n",
    "    if name == \"cora\":\n",
    "        cora_url = 'https://github.com/abojchevski/graph2gauss/raw/master/data/cora_ml.npz'\n",
    "        resp = urlopen(cora_url)\n",
    "        out = read_npz(BytesIO(resp.read()))\n",
    "\n",
    "        G = to_networkx(out, to_undirected=True)\n",
    "\n",
    "        node_classes = {n: out.y[i].item() for i,n in enumerate(list(G.nodes()))}\n",
    "\n",
    "        nx.set_node_attributes(G, node_classes, name = \"target\")\n",
    "\n",
    "\n",
    "\n",
    "        G = G.to_undirected()\n",
    "        CGs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "        CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "        G = CGs[0]\n",
    "\n",
    "        G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "\n",
    "    elif name == \"sbm\":\n",
    "        file_path = os.path.join(root_path, \"sbm/raw/sbm_200.pt\")\n",
    "\n",
    "        adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load(\n",
    "            file_path)\n",
    "\n",
    "        random_graph_selection = np.random.randint(len(adjs))\n",
    "\n",
    "        adj = adjs[random_graph_selection]\n",
    "\n",
    "        g = nx.from_numpy_array(adj.numpy())\n",
    "\n",
    "        these_atom_types = np.ones(g.order())\n",
    "\n",
    "        these_edges, these_types = [], []\n",
    "        for edge in g.edges():\n",
    "            start, end = edge[0], edge[1]\n",
    "            these_edges += [[start, end]]\n",
    "            these_types += [1.]\n",
    "\n",
    "        these_nodes = [(ind, {\"target\": v}) for ind, v in enumerate(these_atom_types)]\n",
    "        these_edges = [(edge[0], edge[1], {\"type\": these_types[ind]}) for ind, edge in enumerate(these_edges)]\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(these_nodes)\n",
    "        G.add_edges_from(these_edges)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        resp = urlopen(\"https://snap.stanford.edu/data/facebook_large.zip\")\n",
    "        myzip = ZipFile(BytesIO(resp.read()))\n",
    "\n",
    "        edgelist = pd.read_csv(myzip.open(\"facebook_large/musae_facebook_edges.csv\"))\n",
    "        G = nx.from_pandas_edgelist(df=edgelist, source=\"id_1\", target=\"id_2\")\n",
    "\n",
    "        class_df = pd.read_csv(myzip.open(\"facebook_large/musae_facebook_target.csv\"))\n",
    "\n",
    "        unique_types = np.unique(class_df[\"page_type\"])\n",
    "        types = {target: i for i, target in enumerate(unique_types.tolist())}\n",
    "\n",
    "        node_classes = {n: types[class_df.at[n, \"page_type\"]] for n in list(G.nodes())}\n",
    "\n",
    "        nx.set_node_attributes(G, node_classes, name=\"target\")\n",
    "\n",
    "\n",
    "    if largest_cc:\n",
    "        CGs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "        CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "        G = CGs[0]\n",
    "    \n",
    "    G = G.copy()\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "\n",
    "    return G\n",
    "    \n",
    "def general_graph_metrics(datamodule, return_values = False, descriptor=\"\", largest_cc=True):\n",
    "\n",
    "    if type(datamodule) == nx.Graph:\n",
    "        G = datamodule\n",
    "    else:\n",
    "        G = datamodule.G\n",
    "        \n",
    "    \n",
    "    if largest_cc:\n",
    "        CGs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "        CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "        G = CGs[0]\n",
    "    \n",
    "    communities = comm.louvain_communities(G, resolution=1)\n",
    "    community_sizes = [len(part) for part in communities]\n",
    "    \n",
    "    # plt.hist(community_sizes)\n",
    "    # plt.show()\n",
    "    \n",
    "    median_size = np.median(community_sizes)\n",
    "    num_communities = len(communities)\n",
    "    \n",
    "    density  = nx.density(G)\n",
    "    try:\n",
    "        diameter = nx.diameter(G)\n",
    "    except:\n",
    "        diameter = -1.\n",
    "    n_nodes  = G.number_of_nodes()\n",
    "    n_edges  = G.number_of_edges()\n",
    "    transitivity = nx.transitivity(G)\n",
    "    clustering   = nx.average_clustering(G)\n",
    "\n",
    "    print(f\"=\" * 50 +\n",
    "          f\"{descriptor}\\n\"\n",
    "          f'\\nN Nodes: {n_nodes}\\n'\n",
    "          f'N Edges: {n_edges}\\n'\n",
    "          f'Num Comms: {num_communities}\\n'\n",
    "          f'Median Comm Size: {median_size}\\n'\n",
    "          f'Density: {density}\\n'\n",
    "          f'Diameter: {diameter}\\n'\n",
    "          f'Transitivity: {transitivity}\\n'\n",
    "          f'Clustering: {clustering}\\n' + \"=\" * 50)\n",
    "\n",
    "    if return_values:\n",
    "        return {\"N Nodes\": n_nodes,\n",
    "               \"N Edges\": n_edges,\n",
    "               \"Density\": density,\n",
    "               \"Diameter\": diameter,\n",
    "               \"Transitivity\": transitivity,\n",
    "               \"Clustering\": clustering}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779fe93-cc5c-42da-b130-8ed89aa01de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_baseline = load_original(\"cora\")\n",
    "\n",
    "# with open(\"../sampling_outputs/cora_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "    \n",
    "# print(G_baseline, G_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a99d5-8275-4462-9b9a-6693bbfe847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = list(range(1,20))\n",
    "print(resolutions)\n",
    "\n",
    "def communities_to_edges(partitions, G):\n",
    "    partition_dict = {}\n",
    "    partitions_h1  = {}\n",
    "    graphs = []\n",
    "    for run in partitions:\n",
    "        for i, p in enumerate(run):\n",
    "            subg = G.subgraph(p)\n",
    "            graphs.append(subg)\n",
    "            \n",
    "\n",
    "    return graphs\n",
    "\n",
    "def make_meta_graph(partition, G):\n",
    "    \"\"\"\n",
    "    Use community algorithm to produce meta-graph of communities and intra-links.\n",
    "    Meta-graph edge weights are the number of inter-community links in original graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get community partition of form {\"community_id\":{\"node_id1\", \"node_id2\", \"node_id3\",...}, ...}\n",
    "    community_to_node = {i: p for i, p in enumerate(partition)}\n",
    "\n",
    "    # Invert community to node, ie new partition = {\"node_id\":\"community_id\", ...}\n",
    "    partition = {}\n",
    "    for comm in community_to_node:\n",
    "        nodes = community_to_node[comm]\n",
    "        for n in nodes:\n",
    "            partition[n] = comm\n",
    "\n",
    "    # self.partition = partition\n",
    "\n",
    "    # Find unique community ids\n",
    "    community_unique = set([k for k in community_to_node.keys()])\n",
    "\n",
    "    # Produce a sub-graph for each community\n",
    "    subgraphs = []\n",
    "    for c in community_unique:\n",
    "        subgraphs.append(nx.subgraph(G, community_to_node[c]))\n",
    "\n",
    "    # Get nested list of edges in original graph\n",
    "    G_edgelist = [[e1, e2] for (e1, e2) in nx.edges(G)]\n",
    "\n",
    "    # Build nested list of edges, of form [[\"community_id1\", \"community_id2\"], [\"community_id3\", \"community_id4\"], ...]\n",
    "    community_edgelist = []\n",
    "    for e in G_edgelist:\n",
    "        comm1 = partition[e[0]]\n",
    "        comm2 = partition[e[1]]\n",
    "\n",
    "        community_edgelist.append((comm1, comm2))\n",
    "\n",
    "    # Find unique edges that are inter-community\n",
    "    unique_comm_edges = list(set(community_edgelist))\n",
    "    out_edges = []\n",
    "    for e in unique_comm_edges:\n",
    "        if (e[1], e[0]) not in out_edges and e[0] != e[1]:\n",
    "            out_edges.append(e)\n",
    "    unique_comm_edges = out_edges\n",
    "\n",
    "    # Build metagraph as a weighted networkx graph\n",
    "    metaG = nx.Graph()\n",
    "    # metaG.add_weighted_edges_from(full_description)\n",
    "    metaG.add_edges_from(unique_comm_edges)\n",
    "\n",
    "    # Set metagraph and community subgraphs as attributes\n",
    "    # self.subgraphs = {i:g for i, g in enumerate(subgraphs)}\n",
    "    return metaG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891ff7a-6b04-4a00-86a1-b53dc15f6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_h2_by_resolution = {}\n",
    "# original_h1_by_resolution = {}\n",
    "# original_statistics_by_resolution = {}\n",
    "\n",
    "# for r in tqdm(resolutions):\n",
    "#     partition = comm.louvain_communities(G_baseline, resolution=r)\n",
    "    \n",
    "#     h1_graphs = communities_to_edges([partition], G_baseline)\n",
    "#     h2_graph  = make_meta_graph(partition, G_baseline)\n",
    "    \n",
    "#     original_h2_by_resolution[r] = h2_graph\n",
    "#     original_h1_by_resolution[r] = h1_graphs\n",
    "    \n",
    "# original_h2_by_resolution = {}\n",
    "# original_h1_by_resolution = {}\n",
    "# original_statistics_by_resolution = {}\n",
    "\n",
    "# for r in tqdm(resolutions):\n",
    "#     partition = comm.louvain_communities(G_baseline, resolution=r)\n",
    "    \n",
    "#     h1_graphs = communities_to_edges([partition], G_baseline)\n",
    "#     h2_graph  = make_meta_graph(partition, G_baseline)\n",
    "    \n",
    "#     original_h2_by_resolution[r] = h2_graph\n",
    "#     original_h1_by_resolution[r] = h1_graphs\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65dc1e-9b57-4710-92b8-df0e05f82875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kstest, ks_2samp, probplot\n",
    "\n",
    "def ks_test_report(G_baseline, G_sampled, algorithm=nx.degree, hist_range=(0,100), name = \"cora\"):\n",
    "    degrees_original = all_metric([G_baseline], algorithm)\n",
    "    degrees_sampled = all_metric([G_sampled], algorithm)\n",
    "    \n",
    "#     excluded_values = [0., 1., 2.]\n",
    "    \n",
    "#     degrees_original = [d for d in degrees_original if float(d) not in excluded_values]\n",
    "#     degrees_sampled = [d for d in degrees_sampled if float(d) not in excluded_values]\n",
    "\n",
    "    report = ks_2samp(degrees_original, degrees_sampled)\n",
    "    print(report)\n",
    "    print(f\"\\nFor {name}:\\n\"\n",
    "          f\"Statistic: {report[0]}\\n\"\n",
    "          f\"P value: {report[1]}\\n\")\n",
    "    \n",
    "    return report[0], report[1]\n",
    "\n",
    "\n",
    "def correlations(G_baseline, G_sampled, algorithm=nx.degree, name = \"cora\"):\n",
    "    degrees_original = all_metric([G_baseline], algorithm, largest_cc=False)\n",
    "    degrees_sampled = all_metric([G_sampled], algorithm, largest_cc=False)\n",
    "    \n",
    "    if algorithm == nx.degree:\n",
    "        hist_range = (0,100)\n",
    "    else:\n",
    "        hist_range = (0., 1.)\n",
    "    \n",
    "    \n",
    "    counts_1, bins = np.histogram(degrees_original, bins=100, range = hist_range)\n",
    "\n",
    "    counts_2, bins = np.histogram(degrees_sampled, bins=100, range = hist_range)\n",
    "    \n",
    "    corr = np.corrcoef(counts_1, counts_2)\n",
    "    \n",
    "    print(f\"Correlation coefficient of {corr[0,1]:.3} for {name}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def all_metric(graphs, metric_algorithm, largest_cc = True):\n",
    "    \n",
    "    \n",
    "    if largest_cc:\n",
    "        CGs = [graphs[0].subgraph(c) for c in nx.connected_components(graphs[0])]\n",
    "        CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "        graphs[0] = CGs[0].copy()\n",
    "        \n",
    "        # graphs[0] = graphs[0].copy().remove_edges_from(nx.selfloop_edges(graphs[0]))\n",
    "    \n",
    "    # for g in graphs:\n",
    "    #     g.remove_edges_from(nx.selfloop_edges(g))\n",
    "        \n",
    "    metric_list = []\n",
    "    \n",
    "    for g in graphs:\n",
    "        for n in list(g.nodes()):\n",
    "            # Some algorithms fail to converge\n",
    "            try:\n",
    "                metric_list.append(metric_algorithm(g, n))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return metric_list\n",
    "\n",
    "class reformat_centrality:\n",
    "    def __init__(self, G):\n",
    "        self.betweeness_dict = nx.betweenness_centrality(G)\n",
    "        \n",
    "    def for_node(self, node):\n",
    "        return self.betweeness_dict[node]\n",
    "\n",
    "\n",
    "def plot_vs(degrees_original, degrees_sampled, degrees_bter, ax, hist_range = (0,100), residual=False):\n",
    "    \n",
    "    \n",
    "    if residual:\n",
    "        counts_1, bins = np.histogram(degrees_original, bins=75, range = hist_range)\n",
    "        counts_1 = counts_1 / np.sum(counts_1)\n",
    "        \n",
    "        counts_2, bins = np.histogram(degrees_sampled, bins=75, range = hist_range)\n",
    "        counts_2 = counts_2 / np.sum(counts_2)\n",
    "        \n",
    "        counts_3, bins = np.histogram(degrees_bter, bins=75, range = hist_range)\n",
    "        counts_3 = counts_3 / np.sum(counts_3)\n",
    "        # ax.errorbar(bins[:-1], counts, xerr=bins[:-1] - bins[1:], label = \"Real (Original)\")\n",
    "        ax.stairs(counts_1 - counts_2, bins,  label = \"HiGGs\", color=\"orange\")\n",
    "        ax.stairs(counts_1 - counts_3, bins,  label = \"BTER\", color=\"green\")\n",
    "        \n",
    "        # ax.scatter(bins[:-1], counts_1 - counts_2,   label = \"HiGGs\", color=\"orange\", marker = \"x\")\n",
    "        # ax.scatter(bins[:-1], counts_1 - counts_3,  label = \"BTER\", color=\"green\", marker = \"x\")\n",
    "        \n",
    "        ax.axhline(linestyle='--', color='blue', alpha=0.5)\n",
    "\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        counts, bins = np.histogram(degrees_original, bins=75, range = hist_range)\n",
    "        counts = counts / np.sum(counts)\n",
    "        # ax.errorbar(bins[:-1], counts, xerr=bins[:-1] - bins[1:], label = \"Real (Original)\")\n",
    "        ax.stairs(counts, bins,  label = \"Real\", color = \"blue\")\n",
    "        # ax.scatter(bins[:-1], counts,   label = \"Real\", color = \"blue\", marker = \"x\")\n",
    "\n",
    "\n",
    "        counts, bins = np.histogram(degrees_sampled, bins=75, range = hist_range)\n",
    "        counts = counts / np.sum(counts)\n",
    "        # ax.errorbar(bins[:-1], counts, xerr=bins[:-1] - bins[1:], label = \"Sythetic (Sampled)\")\n",
    "        ax.stairs(counts, bins,  label = \"HiGGs\", color=\"orange\")\n",
    "        # ax.scatter(bins[:-1], counts,   label = \"HiGGs\", color=\"orange\", marker = \"x\")\n",
    "        \n",
    "        counts, bins = np.histogram(degrees_bter, bins=75, range = hist_range)\n",
    "        counts = counts / np.sum(counts)\n",
    "        # ax.errorbar(bins[:-1], counts, xerr=bins[:-1] - bins[1:], label = \"Sythetic (Sampled)\")\n",
    "        ax.stairs(counts, bins,  label = \"BTER\", color=\"green\")\n",
    "        # ax.scatter(bins[:-1], counts,   label = \"BTER\", color=\"green\", marker = \"x\")\n",
    "        \n",
    "\n",
    "def vis_big_graph(G, largest_cc=False, label = \"\"):\n",
    "    \n",
    "    if largest_cc:\n",
    "        CGs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "        CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "        G = CGs[0]\n",
    "    \n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(G, prog=\"sfdp\", args='-Gsmoothing')\n",
    "\n",
    "    fig, (ax) = plt.subplots(ncols=1, figsize=(6,6))\n",
    "\n",
    "    nx.draw_networkx_edges(G, node_size=2, pos=pos, alpha=0.5, ax = ax)\n",
    "    try:\n",
    "        nx.draw_networkx_nodes(G, node_size = 1, pos = pos, ax = ax,\n",
    "                               node_color=[node[1][\"target\"] for node in G.nodes(data=True)])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout(h_pad=0, w_pad=0, pad=0)\n",
    "    plt.savefig(f\"{label}.png\", dpi=600)\n",
    "    plt.show()\n",
    "        \n",
    "def clean(data, intervals, edge_size=2):\n",
    "    return data[edge_size:-edge_size]\n",
    "        \n",
    "    \n",
    "def plot_all(G_baseline, G_sampled, G_bter, name = \"cora\", clean=False):\n",
    "\n",
    "    \n",
    "    fig, ((ax1, ax2, ax3),(ax4,ax5,ax6)) = plt.subplots(ncols=3, nrows=2, figsize=(12,7), sharex=\"col\")\n",
    "\n",
    "\n",
    "    degrees_original = all_metric([G_baseline], nx.degree)\n",
    "    degrees_sampled = all_metric([G_sampled], nx.degree)\n",
    "    degrees_bter = all_metric([G_bter], nx.degree)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax1, hist_range=(0,75))\n",
    "    # ax1.set_xticks([])\n",
    "    \n",
    "    degrees_original = all_metric([G_baseline], nx.clustering)\n",
    "    degrees_sampled = all_metric([G_sampled], nx.clustering)\n",
    "    degrees_bter = all_metric([G_bter], nx.clustering)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax2, hist_range=(0,1))\n",
    "    # ax2.yaxis.tick_right()\n",
    "    # ax2.set_xticks([])\n",
    "    \n",
    "    degrees_original = all_metric([G_baseline], nx.eccentricity)\n",
    "    degrees_sampled = all_metric([G_sampled], nx.eccentricity)\n",
    "    degrees_bter = all_metric([G_bter], nx.eccentricity)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax3, hist_range=(1,50))\n",
    "    \n",
    "    # ax3.yaxis.tick_right()\n",
    "    # ax3.set_xticks([])\n",
    "\n",
    "    degrees_original = all_metric([G_baseline], nx.degree)\n",
    "    degrees_sampled = all_metric([G_sampled], nx.degree)\n",
    "    degrees_bter = all_metric([G_bter], nx.degree)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax4, hist_range=(0,75), residual=True)\n",
    "    ax4.set_xlabel(\"Degree\")\n",
    "\n",
    "    degrees_original = all_metric([G_baseline], nx.clustering)\n",
    "    degrees_sampled = all_metric([G_sampled], nx.clustering)\n",
    "    degrees_bter = all_metric([G_bter], nx.clustering)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax5, hist_range=(0,1), residual=True)\n",
    "    ax5.set_xlabel(\"Clustering\")\n",
    "    # ax5.yaxis.tick_right()\n",
    "    \n",
    "    degrees_original = all_metric([G_baseline], nx.eccentricity)\n",
    "    degrees_sampled = all_metric([G_sampled], nx.eccentricity)\n",
    "    degrees_bter = all_metric([G_bter], nx.eccentricity)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax6, residual=True, hist_range=(1,50))\n",
    "    ax6.set_xlabel(\"Eccentricity\")\n",
    "    # ax6.yaxis.tick_right()\n",
    "    # ax6.set_xticks([])\n",
    "    \n",
    "    # stat, prob = ks_test_report(G_baseline, G_sampled, algorithm=nx.degree, hist_range=(0,75), name=name+\" degree\")\n",
    "    # ax3.set_title(f\"KS Stat: {stat:.3}, P={prob:.3}\")\n",
    "    \n",
    "    # stat, prob = ks_test_report(G_baseline, G_sampled, algorithm=nx.clustering, hist_range=(0,1), name=name+\" clustering\")\n",
    "    # ax4.set_title(f\"KS Stat: {stat:.3}, P={prob:.3}\")\n",
    "    \n",
    "    correlations(G_baseline, G_sampled, algorithm=nx.degree, name=name+\" degree HiGGs\")\n",
    "    correlations(G_baseline, G_bter, algorithm=nx.degree, name=name+\" degree BTER\")\n",
    "    \n",
    "    correlations(G_baseline, G_sampled, algorithm=nx.clustering, name=name+\" clustering HiGGs\")\n",
    "    correlations(G_baseline, G_bter, algorithm=nx.clustering, name=name+\" clustering BTER\")\n",
    "\n",
    "    ax1.set_ylabel(\"Proportion\")\n",
    "    ax4.set_ylabel(\"Difference (Original - Synthetic)\")\n",
    "    ax3.legend(shadow=True)\n",
    "    # ax4.legend(shadow=True)\n",
    "    plt.tight_layout(h_pad=0)\n",
    "    \n",
    "    plt.savefig(f\"{name}_comparison.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_all_comms(G_baseline, G_sampled, G_bter, name = \"cora\", clean=False):\n",
    "    \n",
    "    fig, ((ax1, ax2, ax3),(ax4,ax5,ax6)) = plt.subplots(ncols=3, nrows=2, figsize=(12,7), sharex=\"col\")\n",
    "\n",
    "\n",
    "    degrees_original = all_metric(G_baseline, nx.degree, largest_cc=False)\n",
    "    degrees_sampled = all_metric(G_sampled, nx.degree, largest_cc=False)\n",
    "    degrees_bter = all_metric(G_bter, nx.degree, largest_cc=False)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax1, hist_range=(0,75))\n",
    "    # ax1.set_xticks([])\n",
    "    \n",
    "    degrees_original = all_metric(G_baseline, nx.clustering, largest_cc=False)\n",
    "    degrees_sampled = all_metric(G_sampled, nx.clustering, largest_cc=False)\n",
    "    degrees_bter = all_metric(G_bter, nx.clustering, largest_cc=False)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax2, hist_range=(0,1))\n",
    "    # ax2.yaxis.tick_right()\n",
    "    # ax2.set_xticks([])\n",
    "    \n",
    "    degrees_original = all_metric(G_baseline, nx.eccentricity, largest_cc=False)\n",
    "    degrees_sampled = all_metric(G_sampled, nx.eccentricity, largest_cc=False)\n",
    "    degrees_bter = all_metric(G_bter, nx.eccentricity, largest_cc=False)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax3, hist_range=(1,50))\n",
    "    \n",
    "    # ax3.yaxis.tick_right()\n",
    "    # ax3.set_xticks([])\n",
    "\n",
    "    degrees_original = all_metric(G_baseline, nx.degree, largest_cc=False)\n",
    "    degrees_sampled = all_metric(G_sampled, nx.degree, largest_cc=False)\n",
    "    degrees_bter = all_metric(G_bter, nx.degree, largest_cc=False)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax4, hist_range=(0,75), residual=True)\n",
    "    ax4.set_xlabel(\"Degree\")\n",
    "\n",
    "    degrees_original = all_metric(G_baseline, nx.clustering, largest_cc=False)\n",
    "    degrees_sampled = all_metric(G_sampled, nx.clustering, largest_cc=False)\n",
    "    degrees_bter = all_metric(G_bter, nx.clustering, largest_cc=False)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax5, hist_range=(0,1), residual=True)\n",
    "    ax5.set_xlabel(\"Clustering\")\n",
    "    # ax5.yaxis.tick_right()\n",
    "    \n",
    "    degrees_original = all_metric(G_baseline, nx.eccentricity, largest_cc=False)\n",
    "    degrees_sampled = all_metric(G_sampled, nx.eccentricity, largest_cc=False)\n",
    "    degrees_bter = all_metric(G_bter, nx.eccentricity, largest_cc=False)\n",
    "    plot_vs(degrees_original, degrees_sampled, degrees_bter, ax6, residual=True, hist_range=(1,50))\n",
    "    ax6.set_xlabel(\"Eccentricity\")\n",
    "    # ax6.yaxis.tick_right()\n",
    "    # ax6.set_xticks([])\n",
    "    \n",
    "    # stat, prob = ks_test_report(G_baseline, G_sampled, algorithm=nx.degree, hist_range=(0,75), name=name+\" degree\")\n",
    "    # ax3.set_title(f\"KS Stat: {stat:.3}, P={prob:.3}\")\n",
    "    \n",
    "    # stat, prob = ks_test_report(G_baseline, G_sampled, algorithm=nx.clustering, hist_range=(0,1), name=name+\" clustering\")\n",
    "    # ax4.set_title(f\"KS Stat: {stat:.3}, P={prob:.3}\")\n",
    "    \n",
    "    # correlations(G_baseline, G_sampled, algorithm=nx.degree, name=name+\" degree HiGGs\")\n",
    "    # correlations(G_baseline, G_bter, algorithm=nx.degree, name=name+\" degree BTER\")\n",
    "    \n",
    "    # correlations(G_baseline, G_sampled, algorithm=nx.clustering, name=name+\" clustering HiGGs\")\n",
    "    # correlations(G_baseline, G_bter, algorithm=nx.clustering, name=name+\" clustering BTER\")\n",
    "\n",
    "    ax1.set_ylabel(\"Proportion\")\n",
    "    ax4.set_ylabel(\"Difference (Original - Synthetic)\")\n",
    "    ax3.legend(shadow=True)\n",
    "    # ax4.legend(shadow=True)\n",
    "    plt.tight_layout(h_pad=0)\n",
    "    \n",
    "    plt.savefig(f\"{name}_comparison.png\")\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31fced6-d7b5-4ed7-9ac4-c32abd31c84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6f086-92fd-4d0a-a939-a8103091b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_baseline = load_original(\"fb_hierarchies\")\n",
    "# vis_big_graph(G_baseline, label=\"Real_fb\")\n",
    "\n",
    "# with open(\"../sampling_outputs/fb_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "# vis_big_graph(G_sampled, label=\"HiGGs_fb\")\n",
    "    \n",
    "# bter = BTER(G_baseline)\n",
    "# bter.fit(1)\n",
    "# G_bter = bter.sample()\n",
    "# G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "# vis_big_graph(G_bter, label=\"BTER_fb\")\n",
    "    \n",
    "# # print(G_baseline, G_sampled, G_bter)    \n",
    "# plot_all(G_baseline, G_sampled, G_bter, name=\"fb\")\n",
    "# general_graph_metrics(G_baseline, descriptor=\"Real_FB\")\n",
    "# general_graph_metrics(G_sampled, descriptor=\"HiGGs_FB\")\n",
    "# general_graph_metrics(G_bter, descriptor=\"BTER_FB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85138be-f403-4e75-869d-6c9d5ee30314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# G_baseline = load_original(\"cora\")\n",
    "# with open(\"../sampling_outputs/cora_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "    \n",
    "# print(G_baseline, G_sampled)    \n",
    "# ks_test_report(G_baseline, G_sampled)\n",
    "\n",
    "# G_baseline = load_original(\"fb_hierarchies\")\n",
    "# with open(\"../sampling_outputs/fb_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "    \n",
    "# print(G_baseline, G_sampled)    \n",
    "# ks_test_report(G_baseline, G_sampled, algorithm=nx.degree, name=\"fb\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5695a-edde-4967-ad89-a30612047e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "# Function from https://stats.stackexchange.com/questions/403652/two-sample-quantile-quantile-plot-in-python\n",
    "def qqplot(x, y, quantiles=None, interpolation='nearest', ax=None, rug=False, color=\"black\",\n",
    "           rug_length=0.05, rug_kwargs=None, label = \"\", **kwargs):\n",
    "    \"\"\"Draw a quantile-quantile plot for `x` versus `y`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like\n",
    "        One-dimensional numeric arrays.\n",
    "\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Axes on which to plot. If not provided, the current axes will be used.\n",
    "\n",
    "    quantiles : int or array-like, optional\n",
    "        Quantiles to include in the plot. This can be an array of quantiles, in\n",
    "        which case only the specified quantiles of `x` and `y` will be plotted.\n",
    "        If this is an int `n`, then the quantiles will be `n` evenly spaced\n",
    "        points between 0 and 1. If this is None, then `min(len(x), len(y))`\n",
    "        evenly spaced quantiles between 0 and 1 will be computed.\n",
    "\n",
    "    interpolation : {‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}\n",
    "        Specify the interpolation method used to find quantiles when `quantiles`\n",
    "        is an int or None. See the documentation for numpy.quantile().\n",
    "\n",
    "    rug : bool, optional\n",
    "        If True, draw a rug plot representing both samples on the horizontal and\n",
    "        vertical axes. If False, no rug plot is drawn.\n",
    "\n",
    "    rug_length : float in [0, 1], optional\n",
    "        Specifies the length of the rug plot lines as a fraction of the total\n",
    "        vertical or horizontal length.\n",
    "\n",
    "    rug_kwargs : dict of keyword arguments\n",
    "        Keyword arguments to pass to matplotlib.axes.Axes.axvline() and\n",
    "        matplotlib.axes.Axes.axhline() when drawing rug plots.\n",
    "\n",
    "    kwargs : dict of keyword arguments\n",
    "        Keyword arguments to pass to matplotlib.axes.Axes.scatter() when drawing\n",
    "        the q-q plot.\n",
    "    \"\"\"\n",
    "    # Get current axes if none are provided\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if quantiles is None:\n",
    "        quantiles = min(len(x), len(y))\n",
    "\n",
    "    # Compute quantiles of the two samples\n",
    "    if isinstance(quantiles, numbers.Integral):\n",
    "        quantiles = np.linspace(start=0, stop=1, num=int(quantiles))\n",
    "    else:\n",
    "        quantiles = np.atleast_1d(np.sort(quantiles))\n",
    "    x_quantiles = np.quantile(x, quantiles, interpolation=interpolation)\n",
    "    y_quantiles = np.quantile(y, quantiles, interpolation=interpolation)\n",
    "\n",
    "    # Draw the rug plots if requested\n",
    "    if rug:\n",
    "        # Default rug plot settings\n",
    "        rug_x_params = dict(ymin=0, ymax=rug_length, c='gray', alpha=0.5)\n",
    "        rug_y_params = dict(xmin=0, xmax=rug_length, c='gray', alpha=0.5)\n",
    "\n",
    "        # Override default setting by any user-specified settings\n",
    "        if rug_kwargs is not None:\n",
    "            rug_x_params.update(rug_kwargs)\n",
    "            rug_y_params.update(rug_kwargs)\n",
    "\n",
    "        # Draw the rug plots\n",
    "        for point in x:\n",
    "            ax.axvline(point, **rug_x_params)\n",
    "        for point in y:\n",
    "            ax.axhline(point, **rug_y_params)\n",
    "\n",
    "    # Draw the q-q plot\n",
    "    ax.scatter(x_quantiles, y_quantiles, s = 10, color=color, marker='x',**kwargs)\n",
    "    ax.plot(x_quantiles, y_quantiles, alpha=0.5, color=color, label = label)\n",
    "    \n",
    "    return ax, x_quantiles, y_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a42cb3-3fd1-436c-80f4-5a8010d59a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_limits(ax):\n",
    "    \n",
    "    xlims = list(ax.get_xlim())\n",
    "    ylims = list(ax.get_ylim())\n",
    "    \n",
    "    lims = xlims + ylims\n",
    "    print(lims)\n",
    "    max_lim = max(lims)\n",
    "    min_lim = min(lims)\n",
    "    \n",
    "    ax.set_xlim([min_lim, max_lim])\n",
    "    ax.set_ylim([min_lim, max_lim])\n",
    "    \n",
    "    # return ax\n",
    "\n",
    "def qq_plots(G_baseline, G_sampled, G_bter, name = \"...\"):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(12,4))\n",
    "\n",
    "    ax1, degree_real, degree_higgs = qqplot(all_metric([G_baseline], nx.degree), all_metric([G_sampled], nx.degree), quantiles=100,    ax=ax1, label = \"HiGGs\", color=\"orange\")\n",
    "    ax2, clustering_real, clustering_higgs  = qqplot(all_metric([G_baseline], nx.clustering), all_metric([G_sampled], nx.clustering), quantiles=100,  ax=ax2, label = \"HiGGs\", color=\"orange\")\n",
    "    ax3, eccentricity_real, eccentricity_higgs  = qqplot(all_metric([G_baseline], nx.eccentricity), all_metric([G_sampled], nx.eccentricity), quantiles=100,  ax=ax3, label = \"HiGGs\", color=\"orange\")\n",
    "    \n",
    "    ax1, degree_real, degree_bter  = qqplot(all_metric([G_baseline], nx.degree), all_metric([G_bter], nx.degree), quantiles=100,    ax=ax1, label = \"BTER\", color=\"green\")\n",
    "    ax2, clustering_real, clustering_bter  = qqplot(all_metric([G_baseline], nx.clustering), all_metric([G_bter], nx.clustering), quantiles=100,  ax=ax2, label = \"BTER\", color=\"green\")\n",
    "    ax3, eccentricity_real, eccentricity_bter  = qqplot(all_metric([G_baseline], nx.eccentricity), all_metric([G_bter], nx.eccentricity), quantiles=100,  ax=ax3, label = \"BTER\", color=\"green\")\n",
    "    \n",
    "    # ax1 = qqplot(all_metric([G_baseline], nx.degree), all_metric([G_baseline], nx.degree), quantiles=100,    ax=ax1, label = \"Real\", color=\"blue\")\n",
    "    # ax2 = qqplot(all_metric([G_baseline], nx.clustering), all_metric([G_baseline], nx.clustering), quantiles=100,  ax=ax2, label = \"Real\", color=\"blue\")\n",
    "    # ax3 = qqplot(all_metric([G_baseline], nx.eccentricity), all_metric([G_baseline], nx.eccentricity), quantiles=100,  ax=ax3, label = \"Real\", color=\"blue\")\n",
    "    # ax1.set_xlim([0,40])\n",
    "    # ax1.set_ylim([0,40])\n",
    "\n",
    "    # ax1.plot([1, ax1.get_xlim()[1]], [1, ax1.get_ylim()[1]], color=\"black\", alpha=0.5, linestyle='--')\n",
    "    # ax2.plot([0, ax2.get_xlim()[1]], [0, ax2.get_ylim()[1]], color=\"black\", alpha=0.5, linestyle='--')\n",
    "    # ax3.plot([0, ax3.get_xlim()[1]], [0, ax3.get_ylim()[1]], color=\"black\", alpha=0.5, linestyle='--')\n",
    "\n",
    "    ax1.set_xlabel('Original Quantiles')\n",
    "    ax1.set_ylabel('Sampled Quantiles')\n",
    "    ax1.set_title('Degree')\n",
    "\n",
    "    ax2.set_xlabel('Original Quantiles')\n",
    "    ax2.set_ylabel('Sampled Quantiles')\n",
    "    ax2.set_title('Clustering')\n",
    "    \n",
    "    ax3.set_xlabel('Original Quantiles')\n",
    "    ax3.set_ylabel('Sampled Quantiles')\n",
    "    ax3.set_title('Eccentricity')\n",
    "    \n",
    "    # square_limits(ax1)\n",
    "    # square_limits(ax2)\n",
    "    # ax3 = square_limits(ax3)\n",
    "    \n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    ax2.legend(shadow=True)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Degree_quantiles_real\"] = degree_real\n",
    "    df[\"Degree_quantiles_higgs\"] = degree_higgs\n",
    "    df[\"Degree_quantiles_bter\"] = degree_bter\n",
    "    \n",
    "    df[\"Clustering_quantiles_real\"] = clustering_real\n",
    "    df[\"Clustering_quantiles_higgs\"] = clustering_higgs\n",
    "    df[\"Clustering_quantiles_bter\"] = clustering_bter\n",
    "\n",
    "    df[\"Eccentricity_quantiles_real\"] = eccentricity_real\n",
    "    df[\"Eccentricity_quantiles_higgs\"] = eccentricity_higgs\n",
    "    df[\"Eccentricity_quantiles_bter\"] = eccentricity_bter\n",
    "    \n",
    "    df.to_csv(f\"{name}.csv\")\n",
    "    \n",
    "    # plt.suptitle(name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"{name}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def qq_plots_comms(G_baseline, G_sampled, G_bter, name = \"...\"):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(12,4))\n",
    "\n",
    "    ax1, degree_real, degree_higgs  = qqplot(all_metric(G_baseline, nx.degree, largest_cc=False), all_metric(G_sampled, nx.degree, largest_cc=False), quantiles=100,    ax=ax1, label = \"HiGGs\", color=\"orange\")\n",
    "    ax2, clustering_real, clustering_higgs   = qqplot(all_metric(G_baseline, nx.clustering, largest_cc=False), all_metric(G_sampled, nx.clustering, largest_cc=False), quantiles=100,  ax=ax2, label = \"HiGGs\", color=\"orange\")\n",
    "    ax3, eccentricity_real, eccentricity_higgs   = qqplot(all_metric(G_baseline, nx.eccentricity, largest_cc=False), all_metric(G_sampled, nx.eccentricity, largest_cc=False), quantiles=100,  ax=ax3, label = \"HiGGs\", color=\"orange\")\n",
    "    \n",
    "    ax1, degree_real, degree_bter   = qqplot(all_metric(G_baseline, nx.degree, largest_cc=False), all_metric(G_bter, nx.degree, largest_cc=False), quantiles=100,    ax=ax1, label = \"BTER\", color=\"green\")\n",
    "    ax2, clustering_real, clustering_bter   = qqplot(all_metric(G_baseline, nx.clustering, largest_cc=False), all_metric(G_bter, nx.clustering, largest_cc=False), quantiles=100,  ax=ax2, label = \"BTER\", color=\"green\")\n",
    "    ax3, eccentricity_real, eccentricity_bter   = qqplot(all_metric(G_baseline, nx.eccentricity, largest_cc=False), all_metric(G_bter, nx.eccentricity, largest_cc=False), quantiles=100,  ax=ax3, label = \"BTER\", color=\"green\")\n",
    "    \n",
    "    # ax1 = qqplot(all_metric(G_baseline, nx.degree, largest_cc=False), all_metric(G_baseline, nx.degree, largest_cc=False), quantiles=100,    ax=ax1, label = \"Real\", color=\"blue\")\n",
    "    # ax2 = qqplot(all_metric(G_baseline, nx.clustering, largest_cc=False), all_metric(G_baseline, nx.clustering, largest_cc=False), quantiles=100,  ax=ax2, label = \"Real\", color=\"blue\")\n",
    "    # ax3 = qqplot(all_metric(G_baseline, nx.eccentricity, largest_cc=False), all_metric(G_baseline, nx.eccentricity, largest_cc=False), quantiles=100,  ax=ax3, label = \"Real\", color=\"blue\")\n",
    "    # ax1.set_xlim([0,40])\n",
    "    # ax1.set_ylim([0,40])\n",
    "\n",
    "    # ax1.plot([1, ax1.get_xlim()[1]], [1, ax1.get_ylim()[1]], color=\"black\", alpha=0.5, linestyle='--')\n",
    "    # ax2.plot([0, ax2.get_xlim()[1]], [0, ax2.get_ylim()[1]], color=\"black\", alpha=0.5, linestyle='--')\n",
    "    # ax3.plot([0, ax3.get_xlim()[1]], [0, ax3.get_ylim()[1]], color=\"black\", alpha=0.5, linestyle='--')\n",
    "\n",
    "    ax1.set_xlabel('Original Quantiles')\n",
    "    ax1.set_ylabel('Sampled Quantiles')\n",
    "    ax1.set_title('Degree')\n",
    "\n",
    "    ax2.set_xlabel('Original Quantiles')\n",
    "    ax2.set_ylabel('Sampled Quantiles')\n",
    "    ax2.set_title('Clustering')\n",
    "    \n",
    "    ax3.set_xlabel('Original Quantiles')\n",
    "    ax3.set_ylabel('Sampled Quantiles')\n",
    "    ax3.set_title('Eccentricity')\n",
    "    \n",
    "    # square_limits(ax1)\n",
    "    # square_limits(ax2)\n",
    "    # ax3 = square_limits(ax3)\n",
    "    \n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    ax2.legend(shadow=True)\n",
    "    \n",
    "    \n",
    "    # plt.suptitle(name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"{name}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Degree_quantiles_real\"] = degree_real\n",
    "    df[\"Degree_quantiles_higgs\"] = degree_higgs\n",
    "    df[\"Degree_quantiles_bter\"] = degree_bter\n",
    "    \n",
    "    df[\"Clustering_quantiles_real\"] = clustering_real\n",
    "    df[\"Clustering_quantiles_higgs\"] = clustering_higgs\n",
    "    df[\"Clustering_quantiles_bter\"] = clustering_bter\n",
    "\n",
    "    df[\"Eccentricity_quantiles_real\"] = eccentricity_real\n",
    "    df[\"Eccentricity_quantiles_higgs\"] = eccentricity_higgs\n",
    "    df[\"Eccentricity_quantiles_bter\"] = eccentricity_bter\n",
    "    \n",
    "    df.to_csv(f\"{name}.csv\")\n",
    "\n",
    "\n",
    "# G_baseline = load_original(\"cora\")\n",
    "# with open(\"../sampling_outputs/cora_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "\n",
    "# bter = BTER(G_baseline)\n",
    "# bter.fit(5)\n",
    "# G_bter = bter.sample()\n",
    "# G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8c225-e6e5-40fa-aa76-b395897f08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_baseline = load_original(\"fb_hierarchies\")\n",
    "# with open(\"../sampling_outputs/fb_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "    \n",
    "# bter = BTER(G_baseline)\n",
    "# bter.fit(1)\n",
    "# G_bter = bter.sample()\n",
    "# G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "\n",
    "# qq_plots(G_baseline, G_sampled, G_bter, name=\"Facebook Page-Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc88dec-df6d-4700-a1d0-52e9fc9633fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "os.chdir(\"../../\")\n",
    "pwd = os.getcwd()\n",
    "dgd_dir = os.path.join(pwd, \"dgd\")\n",
    "sys.path.insert(0, dgd_dir)\n",
    "os.chdir(\"higgs/notepad_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443b208-e886-4075-840e-5efa30841e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869557e9-8028-4437-9a30-1575fde81093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.spectre_utils import FullSampleMetrics, ByClassSampleMetrics, PostProcessSampleMetrics\n",
    "\n",
    "# print(G_baseline, G_sampled, G_bter)    \n",
    "\n",
    "# general_graph_metrics(G_baseline, descriptor=\"Real_Cora\")\n",
    "# general_graph_metrics(G_sampled, descriptor=\"HiGGs_Cora\")\n",
    "# general_graph_metrics(G_bter, descriptor=\"BTER_Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5932e-3b58-443e-a6b4-bb702691d078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e9671-1d22-458f-b9b3-397793f68983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_baseline = load_original(\"cora\")\n",
    "# vis_big_graph(G_baseline, label=\"Real_cora\")\n",
    "\n",
    "# with open(\"/outputs/2023-03-31/09-32-43/sampling/sampled_graph.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "# vis_big_graph(G_sampled, label=\"HiGGs_cora\")\n",
    "\n",
    "# bter = BTER(G_baseline)\n",
    "# bter.fit(1)\n",
    "# G_bter = bter.sample()\n",
    "# G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "\n",
    "\n",
    "# vis_big_graph(G_bter, label=\"BTER_cora\", largest_cc = False)\n",
    "\n",
    "# CGs = [G_bter.subgraph(c) for c in nx.connected_components(G_bter)]\n",
    "# CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "# G_bter = CGs[0]\n",
    "\n",
    "\n",
    "# # plot_all(G_baseline, G_sampled, G_bter)\n",
    "\n",
    "# qq_plots(G_baseline, G_sampled, G_bter, name=f\"CORA_QQ\")\n",
    "\n",
    "# # general_graph_metrics(G_baseline, descriptor=\"Real_Cora\")\n",
    "# # general_graph_metrics(G_sampled, descriptor=\"HiGGs_Cora\")\n",
    "# # general_graph_metrics(G_bter, descriptor=\"BTER_Cora\")\n",
    "\n",
    "# # sampling_metrics = PostProcessSampleMetrics([G_baseline], use_wandb=False)\n",
    "# # print(\"\\nHiGGs\\n---------------------------------------------------------------------------\")\n",
    "# # sampling_metrics([G_sampled], \"MMD scores HiGGs CORA\", 0, 0)\n",
    "# # print(\"\\nBTER\\n---------------------------------------------------------------------------\")\n",
    "# # sampling_metrics([G_bter], \"MMD scores BTER CORA\", 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50f72e-83bb-4a2c-b032-2d9a7282daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# G_baseline = load_original(\"fb_hierarchies\")\n",
    "# vis_big_graph(G_baseline, label=\"Real_fb\")\n",
    "# with open(\"../sampling_outputs/fb_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "#     G_sampled  = pickle.load(f)\n",
    "# vis_big_graph(G_sampled, label=\"HiGGs_fb\")\n",
    "    \n",
    "# bter = BTER(G_baseline)\n",
    "# bter.fit(1)\n",
    "# G_bter = bter.sample()\n",
    "# G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "\n",
    "\n",
    "\n",
    "# vis_big_graph(G_bter, label=\"BTER_fb\", largest_cc = False)\n",
    "\n",
    "# CGs = [G_bter.subgraph(c) for c in nx.connected_components(G_bter)]\n",
    "# CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "# G_bter = CGs[0]\n",
    "\n",
    "# # plot_all(G_baseline, G_sampled, G_bter, name=\"fb\")\n",
    "\n",
    "# qq_plots(G_baseline, G_sampled, G_bter, name=f\"FB_QQ\")\n",
    "\n",
    "\n",
    "# # general_graph_metrics(G_baseline, descriptor=\"Real_fb\")\n",
    "# # general_graph_metrics(G_sampled, descriptor=\"HiGGs_fb\")\n",
    "# # general_graph_metrics(G_bter, descriptor=\"BTER_fb\")\n",
    "\n",
    "# # sampling_metrics = PostProcessSampleMetrics([G_baseline], use_wandb=False)\n",
    "# # print(\"\\nHiGGs\\n---------------------------------------------------------------------------\")\n",
    "# # sampling_metrics([G_sampled], \"MMD scores HiGGs FB\", 0, 0)\n",
    "# # print(\"\\nBTER\\n---------------------------------------------------------------------------\")\n",
    "# # sampling_metrics([G_bter], \"MMD scores BTER FB\", 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64750ba9-30bb-4777-a29d-481d625885c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_communities(graphs, largest_cc=False, label = \"\"):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for g in graphs:\n",
    "        g = nx.convert_node_labels_to_integers(g, first_label = G.order())\n",
    "        G = nx.compose(G, g)\n",
    "    \n",
    "    if largest_cc:\n",
    "        CGs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "        CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "        G = CGs[0]\n",
    "    \n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(G, prog=\"sfdp\", args='-Gsmoothing')\n",
    "\n",
    "    fig, (ax) = plt.subplots(ncols=1, figsize=(6,6))\n",
    "\n",
    "    nx.draw_networkx_edges(G, node_size=2, pos=pos, alpha=0.5, ax = ax)\n",
    "    try:\n",
    "        nx.draw_networkx_nodes(G, node_size = 1, pos = pos, ax = ax,\n",
    "                               node_color=[node[1][\"target\"] for node in G.nodes(data=True)])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout(h_pad=0, w_pad=0, pad=0)\n",
    "    plt.savefig(f\"{label}.png\", dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dca169-23f8-4838-a230-8bc7dac8f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_baseline = load_original(\"cora\")\n",
    "communities_baseline = comm.louvain_communities(G_baseline, resolution=1)\n",
    "communities_baseline = [G_baseline.subgraph(community) for community in communities_baseline]\n",
    "\n",
    "vis_big_graph(G_baseline, label=\"Real_cora\")\n",
    "vis_communities(communities_baseline[:5], label = \"Cora_real_comms\")\n",
    "#================================================================================================================================================\n",
    "\n",
    "with open(\"../sampling_outputs/cora-clustering/sampling/sampled_graph.pkl\", \"rb\") as f:\n",
    "    G_sampled  = pickle.load(f)\n",
    "    \n",
    "communities_sampled = comm.louvain_communities(G_sampled, resolution=1)\n",
    "communities_sampled = [G_sampled.subgraph(community) for community in communities_sampled]\n",
    "vis_big_graph(G_sampled, label=\"HiGGs_cora\")\n",
    "vis_communities(communities_sampled[:5], label = \"Cora_HiGGs_comms\")\n",
    "\n",
    "#================================================================================================================================================\n",
    "\n",
    "bter = BTER(G_baseline)\n",
    "bter.fit(1)\n",
    "G_bter = bter.sample()\n",
    "G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "vis_big_graph(G_bter, label=\"BTER_cora\", largest_cc = False)\n",
    "\n",
    "CGs = [G_bter.subgraph(c) for c in nx.connected_components(G_bter)]\n",
    "CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "G_bter = CGs[0]\n",
    "\n",
    "communities_bter = comm.louvain_communities(G_bter, resolution=1)\n",
    "communities_bter = [G_bter.subgraph(community) for community in communities_bter]\n",
    "\n",
    "\n",
    "vis_communities(communities_bter[:5], label = \"Cora_BTER_comms\")\n",
    "\n",
    "#================================================================================================================================================\n",
    "\n",
    "# plot_all(G_baseline, G_sampled, G_bter, name=\"Cora\")\n",
    "\n",
    "qq_plots(G_baseline, G_sampled, G_bter, name=f\"CORA_QQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be350e-fda3-4631-8b43-db24915cac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================================================================================\n",
    "\n",
    "# general_graph_metrics(G_baseline, descriptor=\"Real_Cora\")\n",
    "# general_graph_metrics(G_sampled, descriptor=\"HiGGs_Cora\")\n",
    "# general_graph_metrics(G_bter, descriptor=\"BTER_Cora\")\n",
    "\n",
    "# sampling_metrics = PostProcessSampleMetrics([G_baseline], use_wandb=False)\n",
    "# print(\"\\nHiGGs\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics([G_sampled], \"MMD scores HiGGs CORA\", 0, 0)\n",
    "# print(\"\\nBTER\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics([G_bter], \"MMD scores BTER CORA\", 0, 0)\n",
    "\n",
    "# plot_all_comms(communities_baseline, communities_sampled, communities_bter, name=\"Cora_Comm\")\n",
    "\n",
    "qq_plots_comms(communities_baseline, communities_sampled, communities_bter, name=f\"CORA_QQ_Comm\")\n",
    "\n",
    "# sampling_metrics = PostProcessSampleMetrics(communities_baseline, use_wandb=False)\n",
    "# # print(\"\\nVS Real\\n---------------------------------------------------------------------------\")\n",
    "# # sampling_metrics([G_baseline.subgraph(community) for community in comm.louvain_communities(G_baseline, resolution=1)], \"MMD scores VS Real CORA\", 0, 0)\n",
    "# print(\"\\nHiGGs\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics(communities_sampled, \"MMD scores HiGGs CORA\", 0, 0)\n",
    "# print(\"\\nBTER\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics(communities_bter, \"MMD scores BTER CORA\", 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63caf0a9-1187-4157-9657-99faa8e6a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_baseline = load_original(\"fb_hierarchies\")\n",
    "\n",
    "communities_baseline = comm.louvain_communities(G_baseline, resolution=1)\n",
    "communities_baseline = [G_baseline.subgraph(community) for community in communities_baseline]\n",
    "vis_big_graph(G_baseline, label=\"Real_fb\", )\n",
    "vis_communities(communities_baseline[:5], label = \"FB_real_comms\")\n",
    "#================================================================================================================================================\n",
    "\n",
    "with open(\"../sampling_outputs/fb-clustering/sampling/fb_sampled_forced_edges.pkl\", \"rb\") as f:\n",
    "    G_sampled  = pickle.load(f)\n",
    "    \n",
    "communities_sampled = comm.louvain_communities(G_sampled, resolution=1)\n",
    "communities_sampled = [G_sampled.subgraph(community) for community in communities_sampled]    \n",
    "\n",
    "vis_big_graph(G_sampled, label=\"HiGGs_fb\")\n",
    "vis_communities(communities_sampled[:5], label = \"FB_HiGGs_comms\")\n",
    "#================================================================================================================================================\n",
    "    \n",
    "bter = BTER(G_baseline)\n",
    "bter.fit(1)\n",
    "G_bter = bter.sample()\n",
    "G_bter.remove_edges_from(nx.selfloop_edges(G_bter))\n",
    "vis_big_graph(G_bter, label=\"BTER_fb\", largest_cc = False)\n",
    "\n",
    "CGs = [G_bter.subgraph(c) for c in nx.connected_components(G_bter)]\n",
    "CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "G_bter = CGs[0]\n",
    "\n",
    "communities_bter = comm.louvain_communities(G_bter, resolution=1)\n",
    "communities_bter = [G_bter.subgraph(community) for community in communities_bter]\n",
    "\n",
    "\n",
    "vis_communities(communities_bter[:5], label = \"FB_bter_comms\")\n",
    "\n",
    "#================================================================================================================================================\n",
    "\n",
    "# plot_all(G_baseline, G_sampled, G_bter, name=\"fb\")\n",
    "\n",
    "qq_plots(G_baseline, G_sampled, G_bter, name=f\"FB_QQ\")\n",
    "\n",
    "#================================================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a863b0f-19ca-4f0e-ad50-8e38d2be644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general_graph_metrics(G_baseline, descriptor=\"Real_fb\")\n",
    "# general_graph_metrics(G_sampled, descriptor=\"HiGGs_fb\")\n",
    "# general_graph_metrics(G_bter, descriptor=\"BTER_fb\")\n",
    "\n",
    "# sampling_metrics = PostProcessSampleMetrics([G_baseline], use_wandb=False)\n",
    "# print(\"\\nHiGGs\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics([G_sampled], \"MMD scores HiGGs FB\", 0, 0)\n",
    "# print(\"\\nBTER\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics([G_bter], \"MMD scores BTER FB\", 0, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CGs = [G_bter.subgraph(c) for c in nx.connected_components(G_bter)]\n",
    "# CGs = sorted(CGs, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "# G_bter = CGs[0]\n",
    "\n",
    "# plot_all_comms(communities_baseline, communities_sampled, communities_bter, name=\"FB_Comm\")\n",
    "\n",
    "qq_plots_comms(communities_baseline, communities_sampled, communities_bter, name=f\"FB_QQ_Comm\")\n",
    "\n",
    "\n",
    "# sampling_metrics = PostProcessSampleMetrics(communities_baseline, use_wandb=False)\n",
    "# # print(\"\\nVS Real\\n---------------------------------------------------------------------------\")\n",
    "# # sampling_metrics([G_baseline.subgraph(community) for community in comm.louvain_communities(G_baseline, resolution=1)], \"MMD scores VS Real FB\", 0, 0)\n",
    "# print(\"\\nHiGGs\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics(communities_sampled, \"MMD scores HiGGs FB\", 0, 0)\n",
    "# print(\"\\nBTER\\n---------------------------------------------------------------------------\")\n",
    "# sampling_metrics(communities_bter, \"MMD scores BTER FB\", 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa4a4c-f76a-4884-9674-7011d8feddee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
